{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks import BackboneFinetuning\n",
    "\n",
    "# seed 고정\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, targets=[]):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    # 학습 및 추론 과정에서 데이터를 1개씩 꺼내오는 곳\n",
    "    def __getitem__(self, idx):\n",
    "        # 정답이 있다면 else문을, 없다면 if문을 수행합니다\n",
    "        if len(self.targets) == 0:\n",
    "            return torch.tensor(self.inputs[idx])\n",
    "        else:\n",
    "            return torch.tensor(self.inputs[idx]), torch.tensor(self.targets[idx])\n",
    "\n",
    "    # 입력하는 개수만큼 데이터를 사용합니다\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "\n",
    "class Dataloader(pl.LightningDataModule):\n",
    "    def __init__(self, model_name, batch_size, shuffle, train_path, dev_path, test_path, predict_path):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.train_path = train_path\n",
    "        self.dev_path = dev_path\n",
    "        self.test_path = test_path\n",
    "        self.predict_path = predict_path\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.predict_dataset = None\n",
    "\n",
    "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, max_length=130)\n",
    "        self.target_columns = ['label']\n",
    "        self.delete_columns = ['id']\n",
    "        self.text_columns = ['sentence_1', 'sentence_2']\n",
    "\n",
    "    def tokenizing(self, dataframe):\n",
    "        data = []\n",
    "        for idx, item in tqdm(dataframe.iterrows(), desc='tokenizing', total=len(dataframe)):\n",
    "            # 두 입력 문장을 [SEP] 토큰으로 이어붙여서 전처리합니다.\n",
    "            text = '[SEP]'.join([item[text_column] for text_column in self.text_columns])\n",
    "            outputs = self.tokenizer(text, add_special_tokens=True, padding='max_length', truncation=True)\n",
    "            data.append(outputs['input_ids'])\n",
    "        return data\n",
    "\n",
    "    def preprocessing(self, data):\n",
    "        # 안쓰는 컬럼을 삭제합니다.\n",
    "        data = data.drop(columns=self.delete_columns)\n",
    "\n",
    "        # 타겟 데이터가 없으면 빈 배열을 리턴합니다.\n",
    "        try:\n",
    "            targets = data[self.target_columns].values.tolist()\n",
    "        except:\n",
    "            targets = []\n",
    "\n",
    "        # 텍스트 데이터를 전처리합니다.\n",
    "        inputs = self.tokenizing(data)\n",
    "\n",
    "        return inputs, targets\n",
    "\n",
    "    def setup(self, stage='fit'):\n",
    "        if stage == 'fit':\n",
    "            # 학습 데이터와 검증 데이터셋을 호출합니다\n",
    "            train_data = pd.read_csv(self.train_path)\n",
    "            val_data = pd.read_csv(self.dev_path)\n",
    "            \n",
    "            train_data['label'] = train_data['label']\n",
    "            augmented_data = train_data.copy()\n",
    "            non_zero_labels = augmented_data[augmented_data['label'] != 0]\n",
    "\n",
    "            non_zero_labels[['sentence_1', 'sentence_2']] = non_zero_labels[['sentence_2', 'sentence_1']]\n",
    "            train_data = pd.concat([train_data, non_zero_labels], ignore_index=True)\n",
    "            # 학습데이터 준비\n",
    "            train_inputs, train_targets = self.preprocessing(train_data)\n",
    "\n",
    "            # 검증데이터 준비\n",
    "            val_inputs, val_targets = self.preprocessing(val_data)\n",
    "\n",
    "            # train 데이터만 shuffle을 적용해줍니다, 필요하다면 val, test 데이터에도 shuffle을 적용할 수 있습니다\n",
    "            self.train_dataset = Dataset(train_inputs, train_targets)\n",
    "            self.val_dataset = Dataset(val_inputs, val_targets)\n",
    "        else:\n",
    "            # 평가데이터 준비\n",
    "            test_data = pd.read_csv(self.test_path)\n",
    "            test_inputs, test_targets = self.preprocessing(test_data)\n",
    "            self.test_dataset = Dataset(test_inputs, test_targets)\n",
    "\n",
    "            predict_data = pd.read_csv(self.predict_path)\n",
    "            predict_inputs, predict_targets = self.preprocessing(predict_data)\n",
    "            self.predict_dataset = Dataset(predict_inputs, [])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=args.shuffle)#, num_workers=5, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.predict_dataset, batch_size=self.batch_size)\n",
    "\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, model_name, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.lr = lr\n",
    "\n",
    "        # 사용할 모델을 호출합니다.\n",
    "        self.plm = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "            pretrained_model_name_or_path=model_name, num_labels=1)\n",
    "        # Loss 계산을 위해 사용될 L1Loss를 호출합니다.\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.plm(x)['logits']\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_func(logits, y.float())\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_func(logits, y.float())\n",
    "        val_pearson = torchmetrics.functional.pearson_corrcoef(logits.squeeze(), y.squeeze())\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "        self.log(\"val_pearson\", val_pearson)\n",
    "        #print(loss, val_pearson)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "\n",
    "        self.log(\"test_pearson\", torchmetrics.functional.pearson_corrcoef(logits.squeeze(), y.squeeze()))\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x = batch\n",
    "        logits = self(x)\n",
    "\n",
    "        return logits.squeeze()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "class EpochPrintCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        print(f\"Epoch {trainer.current_epoch} ended\")\n",
    "        metrics = trainer.callback_metrics\n",
    "        # 검증 손실 출력 (만약 검증을 수행했다면)\n",
    "        if trainer.callback_metrics.get(\"val_loss\"):\n",
    "            print(f\"Validation Loss: {trainer.callback_metrics['val_loss']:.4f}\")\n",
    "        # 학습 손실 출력\n",
    "        if trainer.callback_metrics.get(\"train_loss\"):\n",
    "            print(f\"Training Loss: {trainer.callback_metrics['train_loss']:.4f}\")\n",
    "        if \"val_pearson\" in metrics:\n",
    "            print(f\"Validation Pearson Correlation: {metrics['val_pearson']:.4f}\")\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffa7569cf35447283a37b8a3e7e4296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing:   0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                             | Params\n",
      "---------------------------------------------------------------\n",
      "0 | plm       | ElectraForSequenceClassification | 112 M \n",
      "1 | loss_func | MSELoss                          | 0     \n",
      "---------------------------------------------------------------\n",
      "112 M     Trainable params\n",
      "0         Non-trainable params\n",
      "112 M     Total params\n",
      "451.688   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2df840c221c4cb4b9f5bec34f02ebb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\승범 pc\\Desktop\\공부\\딥러닝\\naver_boot\\플젝\\첫번째\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "c:\\Users\\승범 pc\\Desktop\\공부\\딥러닝\\naver_boot\\플젝\\첫번째\\venv\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The variance of predictions or target is close to zero. This can cause instability in Pearson correlationcoefficient, leading to wrong results. Consider re-scaling the input if possible or computing using alarger dtype (currently using torch.float32).\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "c:\\Users\\승범 pc\\Desktop\\공부\\딥러닝\\naver_boot\\플젝\\첫번째\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f2b3aaaa984fc1a61a58032ecefbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d677907d9c2246c787b38b0fd3ffe092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.448\n",
      "Epoch 0, global step 1033: 'val_pearson' reached 0.89515 (best 0.89515), saving model to './checkpoints\\\\best-model-epoch=00-val_pearson_epoch=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 ended\n",
      "Validation Loss: 0.4477\n",
      "Training Loss: 0.3797\n",
      "Validation Pearson Correlation: 0.8951\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcfe7626786481781197891b1a84eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 2066: 'val_pearson' reached 0.89780 (best 0.89780), saving model to './checkpoints\\\\best-model-epoch=01-val_pearson_epoch=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ended\n",
      "Validation Loss: 0.4684\n",
      "Training Loss: 0.2113\n",
      "Validation Pearson Correlation: 0.8978\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a0c24e67ad415caf8af8af7211211d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.022 >= min_delta = 0.0. New best score: 0.425\n",
      "Epoch 2, global step 3099: 'val_pearson' reached 0.90395 (best 0.90395), saving model to './checkpoints\\\\best-model-epoch=02-val_pearson_epoch=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 ended\n",
      "Validation Loss: 0.4254\n",
      "Training Loss: 0.1531\n",
      "Validation Pearson Correlation: 0.9039\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc40f15c80a46bd9e52dcd406bae17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 4132: 'val_pearson' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 ended\n",
      "Validation Loss: 0.4425\n",
      "Training Loss: 0.1740\n",
      "Validation Pearson Correlation: 0.9022\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e9f6510c654cb0a571dc0301c30bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.0. New best score: 0.409\n",
      "Epoch 4, global step 5165: 'val_pearson' reached 0.91082 (best 0.91082), saving model to './checkpoints\\\\best-model-epoch=04-val_pearson_epoch=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 ended\n",
      "Validation Loss: 0.4095\n",
      "Training Loss: 0.1786\n",
      "Validation Pearson Correlation: 0.9108\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1791a2a081b744819a8961e4b6b85428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.056 >= min_delta = 0.0. New best score: 0.354\n",
      "Epoch 5, global step 6198: 'val_pearson' reached 0.91491 (best 0.91491), saving model to './checkpoints\\\\best-model-epoch=05-val_pearson_epoch=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 ended\n",
      "Validation Loss: 0.3539\n",
      "Training Loss: 0.0837\n",
      "Validation Pearson Correlation: 0.9149\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31eb6493c84a4017acce7a3d21f6916c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 7231: 'val_pearson' reached 0.91512 (best 0.91512), saving model to './checkpoints\\\\best-model-epoch=06-val_pearson_epoch=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 ended\n",
      "Validation Loss: 0.3782\n",
      "Training Loss: 0.0882\n",
      "Validation Pearson Correlation: 0.9151\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ab07e60c914a339d780a5445f1c098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 8264: 'val_pearson' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 ended\n",
      "Validation Loss: 0.4115\n",
      "Training Loss: 0.0349\n",
      "Validation Pearson Correlation: 0.9128\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54f05e99f3c4d40b99b674b5565d332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.345\n",
      "Epoch 8, global step 9297: 'val_pearson' reached 0.91957 (best 0.91957), saving model to './checkpoints\\\\best-model-epoch=08-val_pearson_epoch=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 ended\n",
      "Validation Loss: 0.3447\n",
      "Training Loss: 0.1779\n",
      "Validation Pearson Correlation: 0.9196\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b1a891fce34c0aa212497bab91d47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 10330: 'val_pearson' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 ended\n",
      "Validation Loss: 0.3822\n",
      "Training Loss: 0.0810\n",
      "Validation Pearson Correlation: 0.9164\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bd026cacab41b6a5ef66c7700dfccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 11363: 'val_pearson' reached 0.92227 (best 0.92227), saving model to './checkpoints\\\\best-model-epoch=10-val_pearson_epoch=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 ended\n",
      "Validation Loss: 0.3521\n",
      "Training Loss: 0.0275\n",
      "Validation Pearson Correlation: 0.9223\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5397991bffd4c969a96f721d86a107d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 12396: 'val_pearson' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 ended\n",
      "Validation Loss: 0.3475\n",
      "Training Loss: 0.0272\n",
      "Validation Pearson Correlation: 0.9195\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5336c44e6dcd462eb5a76e130de199a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 13429: 'val_pearson' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 ended\n",
      "Validation Loss: 0.3605\n",
      "Training Loss: 0.0629\n",
      "Validation Pearson Correlation: 0.9178\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063450a27867462d88ee6523c6272322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 14462: 'val_pearson' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 ended\n",
      "Validation Loss: 0.3665\n",
      "Training Loss: 0.0329\n",
      "Validation Pearson Correlation: 0.9171\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fca531c4454840a0ae9e0bc531b3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 15495: 'val_pearson' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 ended\n",
      "Validation Loss: 0.3573\n",
      "Training Loss: 0.0521\n",
      "Validation Pearson Correlation: 0.9185\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\승범 pc\\Desktop\\공부\\딥러닝\\naver_boot\\플젝\\첫번째\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_pearson',  # 모니터링할 메트릭\n",
    "    mode='max',                   # 클수록 ㅁ좋은 것\n",
    "    save_top_k=1,               \n",
    "    #save_last=True,               # 마지막 모델도 저장\n",
    "    filename='best-{model_name}-{epoch:02d}-}',\n",
    "    verbose=True,\n",
    "    dirpath='./checkpoints',      # 체크포인트를 저장할 디렉토리\n",
    ")\n",
    "early_stopping = EarlyStopping('val_loss',patience=10, verbose=True)\n",
    "\n",
    "print('Train Starting...')\n",
    "max_epoch = 50\n",
    "batch_size = 16\n",
    "shuffle = True\n",
    "\n",
    "\n",
    "learning_rate = 1e-5  # 스캐쥴려로 자동\n",
    "model_name = \"monologg/koelectra-base-v3-discriminator\"\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_name', default=model_name, type=str)\n",
    "parser.add_argument('--learning_rate', default=learning_rate, type=float)\n",
    "\n",
    "\n",
    "# 고정값 (상대위치x -> 현재폴더 기준으로(pathlib), )\n",
    "parser.add_argument('--batch_size', default=batch_size, type=int)\n",
    "parser.add_argument('--max_epoch', default=max_epoch, type=int)\n",
    "parser.add_argument('--shuffle', default=shuffle)\n",
    "parser.add_argument('--train_path', default='./data/train_after_hanspell (1).csv')\n",
    "parser.add_argument('--dev_path', default='./data/dev_after_hanspell.csv')\n",
    "parser.add_argument('--test_path', default='./data/dev_after_hanspell.csv')\n",
    "parser.add_argument('--predict_path', default='./data/test_after_hanspell.csv')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# dataloader와 model을 생성합니다.\n",
    "dataloader = Dataloader(args.model_name, args.batch_size, args.shuffle, args.train_path, args.dev_path,\n",
    "                        args.test_path, args.predict_path)\n",
    "model = Model(args.model_name, args.learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "epoch_print_callback = EpochPrintCallback()\n",
    "# gpu가 없으면 accelerator=\"cpu\"로 변경해주세요, gpu가 여러개면 'devices=4'처럼 사용하실 gpu의 개수를 입력해주세요\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, max_epochs=args.max_epoch, log_every_n_steps=1, callbacks=[lr_monitor, epoch_print_callback, checkpoint_callback, early_stopping])\n",
    "\n",
    "# Train part\n",
    "trainer.fit(model=model, datamodule=dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\승범 pc\\Desktop\\공부\\딥러닝\\naver_boot\\플젝\\첫번째\\venv\\Lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:55: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680ecb57f42f459c8798c2b265ea51c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing:   0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2758d91d80443696044e83dbf4b7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing:   0%|          | 0/1100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\승범 pc\\Desktop\\공부\\딥러닝\\naver_boot\\플젝\\첫번째\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c84671085e4eed9b315727cfec9201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_pearson          0.9222691655158997\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "best_model_path = checkpoint_callback.best_model_path\n",
    "model = Model.load_from_checkpoint(best_model_path)\n",
    "trainer.test(model=model, datamodule=dataloader)\n",
    "# 학습이 완료된 모델을 저장합니다.\n",
    "torch.save(model, f'model_{max_epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\승범 pc\\Desktop\\공부\\딥러닝\\naver_boot\\플젝\\첫번째\\venv\\Lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:55: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f38e5cedc5404482b6c2a67d94ede8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing:   0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18f73620b654c37a8159930539d96ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing:   0%|          | 0/1100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\승범 pc\\Desktop\\공부\\딥러닝\\naver_boot\\플젝\\첫번째\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338fac0cfab54af2a415c8baa7e9de11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_path = checkpoint_callback.best_model_path\n",
    "model = Model.load_from_checkpoint(best_model_path)\n",
    "predictions = trainer.predict(model=model, datamodule=dataloader)\n",
    "# 예측된 결과를 형식에 맞게 반올림하여 준비합니다.\n",
    "predictions = list(round(float(i), 1) for i in torch.cat(predictions))\n",
    "# output 형식을 불러와서 예측된 결과로 바꿔주고, output.csv로 출력합니다.\n",
    "output = pd.read_csv('./data/sample_submission.csv')\n",
    "output['target'] = predictions\n",
    "\n",
    "output.to_csv(f'output_base_{max_epoch}_electra_mse.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "# envs\n",
    "\n",
    "# dev(개발)\n",
    "# stg(QA)\n",
    "# prd(운영) -> prd_config.yml\n",
    "\n",
    "# argparser -> dev? stg? prd?\n",
    "\n",
    "# 1가지만의 컨피그 파일을 관리 한다.\n",
    "#  BASE = Path(__file__).resolve().parent # baseline_sb.ipynb /root/jhlee/level1-project/\n",
    "# \n",
    "# git clone level1-project\n",
    "# level1-project \n",
    "# - baseline_sb\n",
    "# - conf\n",
    "#   - config.yml\n",
    "# COFNIG_FILE_PATH = Path(BASE, \"conf\", \"config.yaml\")  # posix(window, mac, linux) 위치 지정 가능 -> C:\\ -> usr/ \n",
    "\n",
    "# datas\n",
    "    # data.csv  # gitingore\n",
    "    # train.csv # gitignore\n",
    "\n",
    "# src\n",
    "    # conf\n",
    "        # config.yaml\n",
    "\n",
    "    # settings  # 프로젝트에서 사용 할 수 있는 공통 상수? 공통적으로 써야 하는 것들\n",
    "        # config.py\n",
    "\n",
    "    # - tokenizer\n",
    "        # - tokenizer.py\n",
    "\n",
    "    # - preprocess\n",
    "    #   - preprocessing.py\n",
    "\n",
    "    # - callbacks.py\n",
    "        # callback.py\n",
    "\n",
    "    # - data\n",
    "    #   - data_loader.py \n",
    "\n",
    "# baseline_sb.ipynb  # -> 사람들한테 공유 하는 목적\n",
    "\n",
    "# main.py  # -> train, test  # 소스코드 동작 목적\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Load config\n",
    "    config = load_config(COFNIG_FILE_PATH)\n",
    "    data_loder_config = config.get(\"data_loader\")  # 상수 설정 값들\n",
    "    data_loder_config[\"tonizer\"] = Tokenizer(model_name)  # 가변 설정 값들\n",
    "\n",
    "    # Create dataloader and model\n",
    "    dataloader = Dataloader(**config.get(\"data_loader\"))\n",
    "    model = Model(config['model_name'], config['learning_rate'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
