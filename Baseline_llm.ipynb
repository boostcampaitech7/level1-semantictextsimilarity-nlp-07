{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.data_loader_config import DATA_LOADER_CONFIG, OPTIMIZER_CONFIG\n",
    "from src.data_loader.loader import Dataloader\n",
    "from src.model.model import Model, Models, LossFunctions\n",
    "from src.trainer.predict import save_result\n",
    "import src.callback as callback\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "\n",
    "# Parameters 설정\n",
    "batch_size = DATA_LOADER_CONFIG['batch_size']\n",
    "shuffle = DATA_LOADER_CONFIG['shuffle']\n",
    "learning_rate = OPTIMIZER_CONFIG['learning_rate']\n",
    "max_epoch = OPTIMIZER_CONFIG['max_epoch']\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "num_workers: int = DATA_LOADER_CONFIG.get('num_workers', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"maywell/Synatra-7B-v0.3-dpo\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 문장을 임베딩으로 변환하는 함수\n",
    "def get_sentence_embedding(sentence, model, tokenizer):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():  # 학습이 아니라 추론이므로 no_grad() 사용\n",
    "        outputs = model(**inputs)\n",
    "    # 문장의 [CLS] 토큰에 해당하는 임베딩을 사용하거나 마지막 layer 평균 사용\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "    return embeddings\n",
    "\n",
    "# 두 문장의 유사도를 계산하는 함수 (코사인 유사도 사용)\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "# 문장 예시\n",
    "sentence1 = \"The cat sits on the mat.\"\n",
    "sentence2 = \"The dog lies on the carpet.\"\n",
    "\n",
    "# 임베딩 생성\n",
    "embedding1 = get_sentence_embedding(sentence1, model, tokenizer)\n",
    "embedding2 = get_sentence_embedding(sentence2, model, tokenizer)\n",
    "\n",
    "# 피어슨 계산\n",
    "pearson_corr, _ = pearsonr(embedding1.cpu().numpy(), embedding2.cpu().numpy())\n",
    "print(f\"Pearson Correlation: {pearson_corr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from scipy.spatial.distance import euclidean\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimilarityEvaluator:\n",
    "    def __init__(self, model_name):\n",
    "        # GPU가 가능하면 사용, 그렇지 않으면 CPU 사용\n",
    "        print(torch.cuda.is_available())\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # 모델과 토크나이저 로드\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name, torch_dtype=torch.float16).to(self.device)\n",
    "\n",
    "    def get_sentence_embedding(self, sentence):\n",
    "        inputs = self.tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "    def compute_cosine_score(self, embedding1, embedding2):\n",
    "        cosine_sim = F.cosine_similarity(embedding1, embedding2, dim=0).item()\n",
    "        # 코사인 유사도를 0 ~ 5 점수로 변환\n",
    "        score = (cosine_sim + 1) * 2.5  # -1 ~ 1 => 0 ~ 5\n",
    "        return min(max(score, 0), 5)  # 0 ~ 5 사이 값으로 클램핑\n",
    "    \n",
    "    def compute_euclidean_score(self, embedding1, embedding2):\n",
    "        # 임베딩 간 유클리디안 거리 계산\n",
    "        distance = euclidean(embedding1.cpu().numpy(), embedding2.cpu().numpy())\n",
    "        # 거리 값을 유사도 점수로 변환 (거리가 작을수록 점수가 높음)\n",
    "        score = max(0, 5 - distance)  # 거리가 0에 가까우면 점수 5, 멀수록 낮아짐\n",
    "        return score\n",
    "\n",
    "def evaluate_similarity(sentence1, sentence2, model_name):\n",
    "    evaluator = SimilarityEvaluator(model_name)\n",
    "    embedding1 = evaluator.get_sentence_embedding(sentence1)\n",
    "    embedding2 = evaluator.get_sentence_embedding(sentence2)\n",
    "    \n",
    "    #cosine_score = evaluator.compute_cosine_score(embedding1, embedding2)\n",
    "    \n",
    "    euclidean_score = evaluator.compute_euclidean_score(embedding1, embedding2)\n",
    "\n",
    "    return euclidean_score\n",
    "\n",
    "# 예시\n",
    "sentence1 = \"여성가족부 명칭 가족부로 바꿔주세요\"\n",
    "sentence2 = \"여성가족부의 이름을 복지부로 바꿔주세요!\"\n",
    "\n",
    "model_name = \"saltlux/Ko-Llama3-Luxia-8B\"\n",
    "score = evaluate_similarity(sentence1, sentence2, model_name)\n",
    "print(f\"Similarity Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(accelerator='gpu', devices='auto', max_epochs=max_epoch, callbacks=[lr_monitor, epoch_print_callback,checkpoint_callback, early_stopping], precision='16-mixed')\n",
    "trainer.fit(model=model, datamodule=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델 불러오기\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "model = Model.load_from_checkpoint(best_model_path, loss_func=LossFunctions.hu_loss)\n",
    "trainer.test(model=model, datamodule=dataloader)\n",
    "# 추론\n",
    "predictions = trainer.predict(model=model, datamodule=dataloader)\n",
    "\n",
    "# 결과 저장\n",
    "save_result(predictions, model_name, max_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
